{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c7f71e4",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 16: File Handling for Business Analytics\n",
    "\n",
    "A huge part of data analysis involves reading data from files and writing results to them. Whether you're processing a sales report, a customer list, or log files, you need to interact with the file system. Python makes this easy.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "- **Opening Files:** Use the `open()` function to open a file. It's best practice to use it with a `with` statement, which automatically closes the file for you, even if errors occur.\n",
    "  ```python\n",
    "  with open('my_report.txt', 'r') as file:\n",
    "      content = file.read()\n",
    "  ```\n",
    "- **File Modes:**\n",
    "  - `'r'`: Read (default). Throws an error if the file doesn't exist.\n",
    "  - `'w'`: Write. Creates a new file or overwrites an existing one.\n",
    "  - `'a'`: Append. Adds content to the end of an existing file.\n",
    "- **Exception Handling:** When working with files, it's crucial to wrap your code in a `try...except FileNotFoundError` block to handle cases where a file might be missing.\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `fh.py`, has been refactored to provide several powerful, reusable functions for common business file-handling tasks.\n",
    "\n",
    "1. **Review the Code:** Open `Day_16_File_Handling/fh.py`. Examine functions like `count_words_and_lines()`, `find_most_common_words()`, `extract_emails_from_file()`, and `analyze_sales_csv()`.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script. It will create a few temporary demo files, run the analysis functions on them, print the results, and then clean up the files.\n",
    "   ```bash\n",
    "   python Day_16_File_Handling/fh.py\n",
    "   ```\n",
    "1. **Run the Tests:** The tests for this lesson are more advanced. They create temporary files in memory to test the functions without needing actual files on your disk.\n",
    "   ```bash\n",
    "   pytest tests/test_day_16.py\n",
    "   ```\n",
    "\n",
    "## ðŸ’» Exercises: Day 16\n",
    "\n",
    "1. **Analyze a Text File:**\n",
    "\n",
    "   - In a new script (`my_solutions_16.py`), create a simple text file named `my_memo.txt` and write a few sentences into it.\n",
    "   - Import the `count_words_and_lines` and `find_most_common_words` functions from the lesson script.\n",
    "   - Call these functions with your new file's path and print the results.\n",
    "\n",
    "1. **Process a Simple CSV:**\n",
    "\n",
    "   - Create a function `create_sales_data(filepath, sales_data)` that takes a list of lists and writes it to a CSV file.\n",
    "   - Your `sales_data` could be `[['Product', 'Price', 'Quantity'], ['Widget A', '10.00', '50'], ['Widget B', '15.50', '30']]`.\n",
    "   - Import and use the `analyze_sales_csv` function from the lesson to read your new CSV and print the total revenue and average transaction value.\n",
    "\n",
    "ðŸŽ‰ **Excellent!** You can now programmatically read from and write to the most common file types. This is a fundamental skill for automating data intake, processing reports, and saving your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abcd76b",
   "metadata": {},
   "source": [
    "English Stop Words Collection for Text Analytics\n",
    "\n",
    "This module provides a comprehensive list of common English stop words\n",
    "used in business text analysis, sentiment analysis, and natural language\n",
    "processing tasks. Stop words are frequently used words that are typically\n",
    "filtered out during text preprocessing to focus on meaningful content.\n",
    "\n",
    "Business Use Cases:\n",
    "- Customer review sentiment analysis\n",
    "- Social media monitoring and brand sentiment\n",
    "- Content analysis of business documents\n",
    "- Market research text mining\n",
    "- Competitor analysis from web content\n",
    "\n",
    "Usage:\n",
    "    from data.stop_words import stop_words\n",
    "\n",
    "    # Filter out stop words from business text\n",
    "    business_text = \"The company has great customer service\"\n",
    "    filtered_words = [word for word in business_text.lower().split()\n",
    "                      if word not in stop_words]\n",
    "    print(filtered_words)  # ['company', 'great', 'customer', 'service']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ec0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "\n",
    "# Comprehensive English stop words list for business text analysis\n",
    "stop_words: List[str] = [\n",
    "    \"i\",\n",
    "    \"me\",\n",
    "    \"my\",\n",
    "    \"myself\",\n",
    "    \"we\",\n",
    "    \"our\",\n",
    "    \"ours\",\n",
    "    \"ourselves\",\n",
    "    \"you\",\n",
    "    \"you're\",\n",
    "    \"you've\",\n",
    "    \"you'll\",\n",
    "    \"you'd\",\n",
    "    \"your\",\n",
    "    \"yours\",\n",
    "    \"yourself\",\n",
    "    \"yourselves\",\n",
    "    \"he\",\n",
    "    \"him\",\n",
    "    \"his\",\n",
    "    \"himself\",\n",
    "    \"she\",\n",
    "    \"she's\",\n",
    "    \"her\",\n",
    "    \"hers\",\n",
    "    \"herself\",\n",
    "    \"it\",\n",
    "    \"it's\",\n",
    "    \"its\",\n",
    "    \"itself\",\n",
    "    \"they\",\n",
    "    \"them\",\n",
    "    \"their\",\n",
    "    \"theirs\",\n",
    "    \"themselves\",\n",
    "    \"what\",\n",
    "    \"which\",\n",
    "    \"who\",\n",
    "    \"whom\",\n",
    "    \"this\",\n",
    "    \"that\",\n",
    "    \"that'll\",\n",
    "    \"these\",\n",
    "    \"those\",\n",
    "    \"am\",\n",
    "    \"is\",\n",
    "    \"are\",\n",
    "    \"was\",\n",
    "    \"were\",\n",
    "    \"be\",\n",
    "    \"been\",\n",
    "    \"being\",\n",
    "    \"have\",\n",
    "    \"has\",\n",
    "    \"had\",\n",
    "    \"having\",\n",
    "    \"do\",\n",
    "    \"does\",\n",
    "    \"did\",\n",
    "    \"doing\",\n",
    "    \"a\",\n",
    "    \"an\",\n",
    "    \"the\",\n",
    "    \"and\",\n",
    "    \"but\",\n",
    "    \"if\",\n",
    "    \"or\",\n",
    "    \"because\",\n",
    "    \"as\",\n",
    "    \"until\",\n",
    "    \"while\",\n",
    "    \"of\",\n",
    "    \"at\",\n",
    "    \"by\",\n",
    "    \"for\",\n",
    "    \"with\",\n",
    "    \"about\",\n",
    "    \"against\",\n",
    "    \"between\",\n",
    "    \"into\",\n",
    "    \"through\",\n",
    "    \"during\",\n",
    "    \"before\",\n",
    "    \"after\",\n",
    "    \"above\",\n",
    "    \"below\",\n",
    "    \"to\",\n",
    "    \"from\",\n",
    "    \"up\",\n",
    "    \"down\",\n",
    "    \"in\",\n",
    "    \"out\",\n",
    "    \"on\",\n",
    "    \"off\",\n",
    "    \"over\",\n",
    "    \"under\",\n",
    "    \"again\",\n",
    "    \"further\",\n",
    "    \"then\",\n",
    "    \"once\",\n",
    "    \"here\",\n",
    "    \"there\",\n",
    "    \"when\",\n",
    "    \"where\",\n",
    "    \"why\",\n",
    "    \"how\",\n",
    "    \"all\",\n",
    "    \"any\",\n",
    "    \"both\",\n",
    "    \"each\",\n",
    "    \"few\",\n",
    "    \"more\",\n",
    "    \"most\",\n",
    "    \"other\",\n",
    "    \"some\",\n",
    "    \"such\",\n",
    "    \"no\",\n",
    "    \"nor\",\n",
    "    \"not\",\n",
    "    \"only\",\n",
    "    \"own\",\n",
    "    \"same\",\n",
    "    \"so\",\n",
    "    \"than\",\n",
    "    \"too\",\n",
    "    \"very\",\n",
    "    \"s\",\n",
    "    \"t\",\n",
    "    \"can\",\n",
    "    \"will\",\n",
    "    \"just\",\n",
    "    \"don\",\n",
    "    \"don't\",\n",
    "    \"should\",\n",
    "    \"should've\",\n",
    "    \"now\",\n",
    "    \"d\",\n",
    "    \"ll\",\n",
    "    \"m\",\n",
    "    \"o\",\n",
    "    \"re\",\n",
    "    \"ve\",\n",
    "    \"y\",\n",
    "    \"ain\",\n",
    "    \"aren\",\n",
    "    \"aren't\",\n",
    "    \"couldn\",\n",
    "    \"couldn't\",\n",
    "    \"didn\",\n",
    "    \"didn't\",\n",
    "    \"doesn\",\n",
    "    \"doesn't\",\n",
    "    \"hadn\",\n",
    "    \"hadn't\",\n",
    "    \"hasn\",\n",
    "    \"hasn't\",\n",
    "    \"haven\",\n",
    "    \"haven't\",\n",
    "    \"isn\",\n",
    "    \"isn't\",\n",
    "    \"ma\",\n",
    "    \"mightn\",\n",
    "    \"mightn't\",\n",
    "    \"mustn\",\n",
    "    \"mustn't\",\n",
    "    \"needn\",\n",
    "    \"needn't\",\n",
    "    \"shan\",\n",
    "    \"shan't\",\n",
    "    \"shouldn\",\n",
    "    \"shouldn't\",\n",
    "    \"wasn\",\n",
    "    \"wasn't\",\n",
    "    \"weren\",\n",
    "    \"weren't\",\n",
    "    \"won\",\n",
    "    \"won't\",\n",
    "    \"wouldn\",\n",
    "    \"wouldn't\",\n",
    "]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
