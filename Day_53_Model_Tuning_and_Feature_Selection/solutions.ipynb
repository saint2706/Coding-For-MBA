{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49761092",
   "metadata": {},
   "source": [
    "# Day 53 â€“ Model Tuning and Feature Selection\n",
    "\n",
    "Optimisation is the bridge between baseline models and production-grade\n",
    "performance. Day 53 introduces reproducible workflows for:\n",
    "\n",
    "- Running grid search and Bayesian optimisation (via `skopt.BayesSearchCV`) to\n",
    "  tune hyperparameters efficiently.\n",
    "- Calculating permutation importance scores to quantify feature contributions.\n",
    "- Applying recursive feature elimination (RFE) and evaluating the reduced\n",
    "  feature set with cross-validation to check that accuracy holds steady.\n",
    "\n",
    "Execute `python Day_53_Model_Tuning_and_Feature_Selection/solutions.py` to see\n",
    "both search strategies in action alongside feature importance diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c535e7ac",
   "metadata": {},
   "source": [
    "Model tuning and feature selection utilities for Day 53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e57ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Categorical, Real\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TuningResult:\n",
    "    \"\"\"Lightweight container for fitted search objects.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    search: object\n",
    "    best_params: Dict[str, object]\n",
    "    best_score: float\n",
    "\n",
    "\n",
    "def generate_tuning_dataset(\n",
    "    n_samples: int = 300,\n",
    "    n_features: int = 10,\n",
    "    n_informative: int = 5,\n",
    "    class_sep: float = 2.0,\n",
    "    random_state: int = 53,\n",
    ") -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Create a deterministic binary classification dataset for tuning demos.\"\"\"\n",
    "\n",
    "    X, y = make_classification(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        n_redundant=0,\n",
    "        n_repeated=0,\n",
    "        class_sep=class_sep,\n",
    "        flip_y=0.01,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def build_logistic_pipeline(random_state: int = 53) -> Pipeline:\n",
    "    \"\"\"Return a scaled logistic regression pipeline.\"\"\"\n",
    "\n",
    "    return make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=2000, solver=\"lbfgs\", random_state=random_state),\n",
    "    )\n",
    "\n",
    "\n",
    "def run_grid_search(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    param_grid: Dict[str, Iterable[float | int]] | None = None,\n",
    "    cv: int = 5,\n",
    "    scoring: str = \"roc_auc\",\n",
    "    random_state: int = 53,\n",
    ") -> TuningResult:\n",
    "    \"\"\"Execute a deterministic grid search for logistic regression hyperparameters.\"\"\"\n",
    "\n",
    "    pipeline = build_logistic_pipeline(random_state=random_state)\n",
    "    if param_grid is None:\n",
    "        param_grid = {\n",
    "            \"logisticregression__C\": [0.1, 1.0, 10.0],\n",
    "            \"logisticregression__penalty\": [\"l2\"],\n",
    "        }\n",
    "    cv_strategy = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    grid = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=cv_strategy,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "    grid.fit(X, y)\n",
    "    return TuningResult(\n",
    "        name=\"grid_search\",\n",
    "        search=grid,\n",
    "        best_params=grid.best_params_,\n",
    "        best_score=float(grid.best_score_),\n",
    "    )\n",
    "\n",
    "\n",
    "def run_bayesian_optimisation(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    search_spaces: Dict[str, Iterable] | None = None,\n",
    "    n_iter: int = 16,\n",
    "    cv: int = 5,\n",
    "    scoring: str = \"roc_auc\",\n",
    "    random_state: int = 53,\n",
    ") -> TuningResult:\n",
    "    \"\"\"Perform Bayesian optimisation using scikit-optimize's BayesSearchCV.\"\"\"\n",
    "\n",
    "    pipeline = build_logistic_pipeline(random_state=random_state)\n",
    "    if search_spaces is None:\n",
    "        search_spaces = {\n",
    "            \"logisticregression__C\": Real(1e-2, 1e2, prior=\"log-uniform\"),\n",
    "            \"logisticregression__penalty\": Categorical([\"l2\"]),\n",
    "        }\n",
    "    cv_strategy = StratifiedKFold(n_splits=cv, shuffle=True, random_state=random_state)\n",
    "    bayes = BayesSearchCV(\n",
    "        pipeline,\n",
    "        search_spaces=search_spaces,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv_strategy,\n",
    "        scoring=scoring,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "    )\n",
    "    bayes.fit(X, y)\n",
    "    return TuningResult(\n",
    "        name=\"bayesian_search\",\n",
    "        search=bayes,\n",
    "        best_params=bayes.best_params_,\n",
    "        best_score=float(bayes.best_score_),\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_permutation_importance(\n",
    "    model,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_repeats: int = 15,\n",
    "    random_state: int = 53,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Return permutation importance scores as a DataFrame.\"\"\"\n",
    "\n",
    "    result = permutation_importance(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        n_repeats=n_repeats,\n",
    "        random_state=random_state,\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"feature\": [f\"feature_{i}\" for i in range(X.shape[1])],\n",
    "            \"importance_mean\": result.importances_mean,\n",
    "            \"importance_std\": result.importances_std,\n",
    "        }\n",
    "    ).sort_values(\"importance_mean\", ascending=False)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def run_recursive_feature_elimination(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    n_features_to_select: int = 5,\n",
    "    random_state: int = 53,\n",
    ") -> Tuple[RFE, np.ndarray]:\n",
    "    \"\"\"Perform recursive feature elimination with logistic regression.\"\"\"\n",
    "\n",
    "    estimator = LogisticRegression(\n",
    "        max_iter=2000, solver=\"lbfgs\", random_state=random_state\n",
    "    )\n",
    "    selector = RFE(estimator, n_features_to_select=n_features_to_select)\n",
    "    selector.fit(X, y)\n",
    "    support = selector.support_\n",
    "    return selector, support\n",
    "\n",
    "\n",
    "def evaluate_selected_features(\n",
    "    selector: RFE,\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cv: int = 5,\n",
    ") -> float:\n",
    "    \"\"\"Evaluate the selected features with cross-validation accuracy.\"\"\"\n",
    "\n",
    "    X_selected = selector.transform(X)\n",
    "    model = LogisticRegression(max_iter=2000)\n",
    "    scores = cross_val_score(model, X_selected, y, cv=cv, scoring=\"accuracy\")\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "\n",
    "def run_day53_demo() -> Dict[str, TuningResult]:\n",
    "    \"\"\"Execute grid search and Bayesian optimisation workflows.\"\"\"\n",
    "\n",
    "    X, y = generate_tuning_dataset()\n",
    "    grid = run_grid_search(X, y)\n",
    "    bayes = run_bayesian_optimisation(X, y)\n",
    "\n",
    "    pipeline = grid.search.best_estimator_\n",
    "    permutation_df = compute_permutation_importance(pipeline, X, y)\n",
    "    selector, support = run_recursive_feature_elimination(X, y)\n",
    "    selected_score = evaluate_selected_features(selector, X, y)\n",
    "\n",
    "    print(\"Permutation importance head:\\n\", permutation_df.head())\n",
    "    print(\"Selected features:\", np.where(support)[0])\n",
    "    print(f\"Cross-validated accuracy with selected features: {selected_score:.3f}\")\n",
    "\n",
    "    return {\n",
    "        \"grid\": grid,\n",
    "        \"bayes\": bayes,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_day53_demo()\n",
    "    for name, result in results.items():\n",
    "        print(f\"{name}: best score = {result.best_score:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
