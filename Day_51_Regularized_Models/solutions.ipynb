{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeab68ed",
   "metadata": {},
   "source": [
    "# Day 51 â€“ Regularised Models\n",
    "\n",
    "This lesson extends the regression toolkit with L2 (ridge), L1 (lasso), and\n",
    "elastic net penalties before introducing generalised linear models (GLMs). The\n",
    "core notebook and `solutions.py` module walk through the following:\n",
    "\n",
    "- Building a reproducible synthetic regression dataset and benchmarking ridge,\n",
    "  lasso, and elastic net pipelines with cross-validation.\n",
    "- Measuring coefficient shrinkage to understand how regularisation combats\n",
    "  overfitting and highlights the most important predictors.\n",
    "- Training a Poisson regression GLM for count outcomes so you can generalise\n",
    "  linear modelling concepts beyond ordinary least squares.\n",
    "\n",
    "Run `python Day_51_Regularized_Models/solutions.py` to execute the full demo and\n",
    "review the printed comparison table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1011a4d",
   "metadata": {},
   "source": [
    "Utilities for exploring regularised linear models in Day 51."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3461bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import (\n",
    "    ElasticNet,\n",
    "    Lasso,\n",
    "    LinearRegression,\n",
    "    PoissonRegressor,\n",
    "    Ridge,\n",
    ")\n",
    "from sklearn.metrics import mean_poisson_deviance\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RegularisedModelResult:\n",
    "    \"\"\"Container for a fitted regularised model and its metrics.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    pipeline: Pipeline\n",
    "    cv_score: float\n",
    "\n",
    "\n",
    "def load_synthetic_regression(\n",
    "    n_samples: int = 200,\n",
    "    n_features: int = 12,\n",
    "    n_informative: int = 6,\n",
    "    noise: float = 8.0,\n",
    "    random_state: int = 51,\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Return a deterministic regression dataset with informative coefficients.\"\"\"\n",
    "\n",
    "    X, y, true_coef = make_regression(\n",
    "        n_samples=n_samples,\n",
    "        n_features=n_features,\n",
    "        n_informative=n_informative,\n",
    "        noise=noise,\n",
    "        coef=True,\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    return X, y, true_coef\n",
    "\n",
    "\n",
    "def build_regularised_pipeline(\n",
    "    model: str,\n",
    "    alpha: float = 1.0,\n",
    "    l1_ratio: float = 0.5,\n",
    "    random_state: int | None = 51,\n",
    ") -> Pipeline:\n",
    "    \"\"\"Create a standardised pipeline for the requested regularised estimator.\"\"\"\n",
    "\n",
    "    if model == \"ridge\":\n",
    "        estimator = Ridge(alpha=alpha, random_state=random_state)\n",
    "    elif model == \"lasso\":\n",
    "        estimator = Lasso(alpha=alpha, random_state=random_state, max_iter=5000)\n",
    "    elif model == \"elastic_net\":\n",
    "        estimator = ElasticNet(\n",
    "            alpha=alpha, l1_ratio=l1_ratio, random_state=random_state, max_iter=5000\n",
    "        )\n",
    "    elif model == \"linear\":\n",
    "        estimator = LinearRegression()\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model '{model}'.\")\n",
    "    return make_pipeline(StandardScaler(), estimator)\n",
    "\n",
    "\n",
    "def evaluate_models_with_cv(\n",
    "    pipelines: Dict[str, Pipeline],\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    cv: int = 5,\n",
    "    scoring: str = \"neg_mean_squared_error\",\n",
    ") -> Dict[str, RegularisedModelResult]:\n",
    "    \"\"\"Fit each pipeline with cross-validation and capture their scores.\"\"\"\n",
    "\n",
    "    splitter = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    results: Dict[str, RegularisedModelResult] = {}\n",
    "    for name, pipeline in pipelines.items():\n",
    "        scores = cross_val_score(pipeline, X, y, scoring=scoring, cv=splitter)\n",
    "        pipeline.fit(X, y)\n",
    "        results[name] = RegularisedModelResult(\n",
    "            name=name, pipeline=pipeline, cv_score=float(np.mean(scores))\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "def summarise_coefficients(\n",
    "    results: Dict[str, RegularisedModelResult],\n",
    ") -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"Report coefficient shrinkage statistics for fitted regularised models.\"\"\"\n",
    "\n",
    "    summary: Dict[str, Dict[str, float]] = {}\n",
    "    for name, result in results.items():\n",
    "        estimator = result.pipeline[-1]\n",
    "        if not hasattr(estimator, \"coef_\"):\n",
    "            continue\n",
    "        coef = estimator.coef_\n",
    "        summary[name] = {\n",
    "            \"l1_norm\": float(np.sum(np.abs(coef))),\n",
    "            \"l2_norm\": float(np.sqrt(np.sum(coef**2))),\n",
    "            \"non_zero\": int(np.count_nonzero(np.abs(coef) > 1e-8)),\n",
    "        }\n",
    "    return summary\n",
    "\n",
    "\n",
    "def fit_poisson_glm(\n",
    "    X: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "    alpha: float = 0.0,\n",
    "    max_iter: int = 500,\n",
    "    random_state: int | None = 51,\n",
    ") -> Tuple[Pipeline, float]:\n",
    "    \"\"\"Fit a Poisson regression GLM and return the model with its deviance.\"\"\"\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        StandardScaler(with_mean=False),\n",
    "        PoissonRegressor(alpha=alpha, max_iter=max_iter, fit_intercept=True),\n",
    "    )\n",
    "    pipeline.fit(X, y)\n",
    "    preds = pipeline.predict(X)\n",
    "    deviance = mean_poisson_deviance(y, preds)\n",
    "    return pipeline, float(deviance)\n",
    "\n",
    "\n",
    "def run_day51_demo() -> Dict[str, RegularisedModelResult]:\n",
    "    \"\"\"Train ridge, lasso, and elastic net pipelines on the synthetic dataset.\"\"\"\n",
    "\n",
    "    X, y, _ = load_synthetic_regression()\n",
    "    models = {\n",
    "        \"linear\": build_regularised_pipeline(\"linear\"),\n",
    "        \"ridge\": build_regularised_pipeline(\"ridge\", alpha=1.0),\n",
    "        \"lasso\": build_regularised_pipeline(\"lasso\", alpha=0.05),\n",
    "        \"elastic_net\": build_regularised_pipeline(\n",
    "            \"elastic_net\", alpha=0.08, l1_ratio=0.5\n",
    "        ),\n",
    "    }\n",
    "    results = evaluate_models_with_cv(models, X, y)\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fitted = run_day51_demo()\n",
    "    coefficient_summary = summarise_coefficients(fitted)\n",
    "    print(\"Day 51 Regularised Models Demo\")\n",
    "    for name, result in fitted.items():\n",
    "        print(f\"- {name}: CV score (neg MSE) = {result.cv_score:.3f}\")\n",
    "    print(\"\\nCoefficient summary:\")\n",
    "    for name, stats in coefficient_summary.items():\n",
    "        print(\n",
    "            f\"- {name}: L1 {stats['l1_norm']:.2f}, L2 {stats['l2_norm']:.2f}, non-zero {stats['non_zero']}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
