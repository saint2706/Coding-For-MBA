{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb40cdc6",
   "metadata": {},
   "source": [
    "# Day 63 â€“ Causal Inference and Uplift Modeling\n",
    "\n",
    "Understand how experimentation and counterfactual reasoning quantify impact. After this lesson you will:\n",
    "\n",
    "- Estimate average treatment effects (ATE) from randomized A/B tests.\n",
    "- Learn propensity score workflows for observational studies.\n",
    "- Implement double machine learning with cross-fitted residualization.\n",
    "- Build two-model uplift estimators to target incremental responders.\n",
    "\n",
    "Run `python Day_63_Causal_Inference_and_Uplift/solutions.py` to generate synthetic treatment data, estimate effects with multiple techniques, and visualise uplift segmentations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d703edd",
   "metadata": {},
   "source": [
    "Causal inference utilities for Day 63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ABTestResult:\n",
    "    \"\"\"Summary statistics for a difference-in-means test.\"\"\"\n",
    "\n",
    "    lift: float\n",
    "    stderr: float\n",
    "    ci_low: float\n",
    "    ci_high: float\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PropensityModel:\n",
    "    \"\"\"Logistic regression coefficients for propensity scores.\"\"\"\n",
    "\n",
    "    weights: np.ndarray\n",
    "    feature_mean: np.ndarray\n",
    "    feature_scale: np.ndarray\n",
    "\n",
    "    def _scale(self, features: np.ndarray) -> np.ndarray:\n",
    "        scaled = features.copy()\n",
    "        scaled[:, 1:] = (scaled[:, 1:] - self.feature_mean) / (\n",
    "            self.feature_scale + 1e-12\n",
    "        )\n",
    "        return scaled\n",
    "\n",
    "    def predict_proba(self, features: np.ndarray) -> np.ndarray:\n",
    "        logits = self._scale(features) @ self.weights\n",
    "        return 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DoubleMLResult:\n",
    "    \"\"\"Double machine learning effect estimate.\"\"\"\n",
    "\n",
    "    ate: float\n",
    "    nuisance_r2: Tuple[float, float]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class UpliftResult:\n",
    "    \"\"\"Two-model uplift estimates for targeting.\"\"\"\n",
    "\n",
    "    treatment_response: float\n",
    "    control_response: float\n",
    "    uplift: float\n",
    "\n",
    "\n",
    "def generate_synthetic_treatment_data(\n",
    "    n: int = 600, random_state: int = 63\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Create observational data with known treatment effect.\"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    age = rng.integers(18, 65, size=n)\n",
    "    browsing_time = rng.normal(4.0, 1.0, size=n)\n",
    "    income = rng.normal(55_000, 8_000, size=n)\n",
    "    baseline = 0.1 + 0.002 * (age - 30) + 0.00001 * (income - 50_000)\n",
    "    propensity_logits = -0.5 + 0.04 * (browsing_time - 4) + 0.00003 * (income - 55_000)\n",
    "    propensity = 1.0 / (1.0 + np.exp(-propensity_logits))\n",
    "    treatment = rng.binomial(1, propensity)\n",
    "    true_effect = 0.15\n",
    "    outcome = np.clip(\n",
    "        baseline + true_effect * treatment + 0.005 * (browsing_time - 4), 0, 1\n",
    "    )\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"age\": age,\n",
    "            \"browsing_time\": browsing_time,\n",
    "            \"income\": income,\n",
    "            \"treatment\": treatment,\n",
    "            \"outcome\": outcome,\n",
    "            \"true_propensity\": propensity,\n",
    "            \"true_effect\": np.repeat(true_effect, n),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def difference_in_means(data: pd.DataFrame) -> ABTestResult:\n",
    "    \"\"\"Compute lift and confidence interval for a randomized test.\"\"\"\n",
    "\n",
    "    treated = data[data[\"treatment\"] == 1][\"outcome\"].to_numpy(dtype=float)\n",
    "    control = data[data[\"treatment\"] == 0][\"outcome\"].to_numpy(dtype=float)\n",
    "    lift = treated.mean() - control.mean()\n",
    "    stderr = np.sqrt(\n",
    "        treated.var(ddof=1) / treated.size + control.var(ddof=1) / control.size\n",
    "    )\n",
    "    ci_low = lift - 1.96 * stderr\n",
    "    ci_high = lift + 1.96 * stderr\n",
    "    return ABTestResult(\n",
    "        lift=float(lift),\n",
    "        stderr=float(stderr),\n",
    "        ci_low=float(ci_low),\n",
    "        ci_high=float(ci_high),\n",
    "    )\n",
    "\n",
    "\n",
    "def _prepare_design_matrix(\n",
    "    data: pd.DataFrame, include_intercept: bool = True\n",
    ") -> np.ndarray:\n",
    "    features = data[[\"age\", \"browsing_time\", \"income\"]].to_numpy(dtype=float)\n",
    "    if include_intercept:\n",
    "        return np.column_stack([np.ones(len(data)), features])\n",
    "    return features\n",
    "\n",
    "\n",
    "def fit_propensity_model(\n",
    "    data: pd.DataFrame, lr: float = 0.05, epochs: int = 800\n",
    ") -> PropensityModel:\n",
    "    \"\"\"Fit logistic regression via gradient descent for propensity scores.\"\"\"\n",
    "\n",
    "    X = _prepare_design_matrix(data)\n",
    "    y = data[\"treatment\"].to_numpy(dtype=float)\n",
    "    feature_mean = X[:, 1:].mean(axis=0)\n",
    "    feature_scale = X[:, 1:].std(axis=0) + 1e-6\n",
    "    X_scaled = X.copy()\n",
    "    X_scaled[:, 1:] = (X_scaled[:, 1:] - feature_mean) / feature_scale\n",
    "    weights = np.zeros(X.shape[1], dtype=float)\n",
    "    for _ in range(epochs):\n",
    "        logits = X_scaled @ weights\n",
    "        preds = 1.0 / (1.0 + np.exp(-logits))\n",
    "        gradient = X_scaled.T @ (preds - y) / len(y)\n",
    "        weights -= lr * gradient\n",
    "    return PropensityModel(\n",
    "        weights=weights, feature_mean=feature_mean, feature_scale=feature_scale\n",
    "    )\n",
    "\n",
    "\n",
    "def estimate_ipw_ate(data: pd.DataFrame, propensity_model: PropensityModel) -> float:\n",
    "    \"\"\"Inverse propensity weighting estimate of the treatment effect.\"\"\"\n",
    "\n",
    "    X = _prepare_design_matrix(data)\n",
    "    propensities = propensity_model.predict_proba(X)\n",
    "    treated = data[\"treatment\"].to_numpy(dtype=float)\n",
    "    outcome = data[\"outcome\"].to_numpy(dtype=float)\n",
    "    weights_treated = treated / (propensities + 1e-12)\n",
    "    weights_control = (1 - treated) / (1 - propensities + 1e-12)\n",
    "    ate = (weights_treated @ outcome) / weights_treated.sum() - (\n",
    "        weights_control @ outcome\n",
    "    ) / weights_control.sum()\n",
    "    return float(ate)\n",
    "\n",
    "\n",
    "def _linear_regression(X: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    beta, *_ = np.linalg.lstsq(X, y, rcond=None)\n",
    "    return beta\n",
    "\n",
    "\n",
    "def double_machine_learning(data: pd.DataFrame) -> DoubleMLResult:\n",
    "    \"\"\"Compute double ML ATE with two-fold cross fitting.\"\"\"\n",
    "\n",
    "    n = len(data)\n",
    "    fold = n // 2\n",
    "    indices = np.arange(n)\n",
    "    X = data[[\"age\", \"browsing_time\", \"income\"]].to_numpy(dtype=float)\n",
    "    T = data[\"treatment\"].to_numpy(dtype=float)\n",
    "    Y = data[\"outcome\"].to_numpy(dtype=float)\n",
    "    residuals_y = np.zeros_like(Y)\n",
    "    residuals_t = np.zeros_like(T)\n",
    "    r2_y: List[float] = []  # type: ignore[name-defined]\n",
    "    r2_t: List[float] = []  # type: ignore[name-defined]\n",
    "    for train_idx, test_idx in (\n",
    "        (indices[:fold], indices[fold:]),\n",
    "        (indices[fold:], indices[:fold]),\n",
    "    ):\n",
    "        X_train = X[train_idx]\n",
    "        X_test = X[test_idx]\n",
    "        Y_train = Y[train_idx]\n",
    "        T_train = T[train_idx]\n",
    "        X_design_train = np.column_stack([np.ones(len(train_idx)), X_train])\n",
    "        beta_y = _linear_regression(X_design_train, Y_train)\n",
    "        beta_t = _linear_regression(X_design_train, T_train)\n",
    "        X_design_test = np.column_stack([np.ones(len(test_idx)), X_test])\n",
    "        y_hat = X_design_test @ beta_y\n",
    "        t_hat = X_design_test @ beta_t\n",
    "        residuals_y[test_idx] = Y[test_idx] - y_hat\n",
    "        residuals_t[test_idx] = T[test_idx] - t_hat\n",
    "        ss_tot_y = np.sum((Y[train_idx] - Y[train_idx].mean()) ** 2)\n",
    "        ss_res_y = np.sum((Y_train - X_design_train @ beta_y) ** 2)\n",
    "        ss_tot_t = np.sum((T_train - T_train.mean()) ** 2)\n",
    "        ss_res_t = np.sum((T_train - X_design_train @ beta_t) ** 2)\n",
    "        r2_y.append(1 - ss_res_y / (ss_tot_y + 1e-12))\n",
    "        r2_t.append(1 - ss_res_t / (ss_tot_t + 1e-12))\n",
    "    ate = float(\n",
    "        np.dot(residuals_t, residuals_y) / (np.dot(residuals_t, residuals_t) + 1e-12)\n",
    "    )\n",
    "    return DoubleMLResult(\n",
    "        ate=ate, nuisance_r2=(float(np.mean(r2_y)), float(np.mean(r2_t)))\n",
    "    )\n",
    "\n",
    "\n",
    "def two_model_uplift(data: pd.DataFrame) -> UpliftResult:\n",
    "    \"\"\"Estimate uplift using separate treatment and control response models.\"\"\"\n",
    "\n",
    "    treated = data[data[\"treatment\"] == 1]\n",
    "    control = data[data[\"treatment\"] == 0]\n",
    "    features_treated = np.column_stack(\n",
    "        [\n",
    "            np.ones(len(treated)),\n",
    "            treated[[\"age\", \"browsing_time\", \"income\"]].to_numpy(dtype=float),\n",
    "        ]\n",
    "    )\n",
    "    features_control = np.column_stack(\n",
    "        [\n",
    "            np.ones(len(control)),\n",
    "            control[[\"age\", \"browsing_time\", \"income\"]].to_numpy(dtype=float),\n",
    "        ]\n",
    "    )\n",
    "    beta_treated = _linear_regression(\n",
    "        features_treated, treated[\"outcome\"].to_numpy(dtype=float)\n",
    "    )\n",
    "    beta_control = _linear_regression(\n",
    "        features_control, control[\"outcome\"].to_numpy(dtype=float)\n",
    "    )\n",
    "    cohort = data[[\"age\", \"browsing_time\", \"income\"]].to_numpy(dtype=float)\n",
    "    cohort_design = np.column_stack([np.ones(len(cohort)), cohort])\n",
    "    treatment_pred = float(np.mean(cohort_design @ beta_treated))\n",
    "    control_pred = float(np.mean(cohort_design @ beta_control))\n",
    "    uplift = treatment_pred - control_pred\n",
    "    return UpliftResult(\n",
    "        treatment_response=treatment_pred,\n",
    "        control_response=control_pred,\n",
    "        uplift=uplift,\n",
    "    )\n",
    "\n",
    "\n",
    "def run_causal_suite(random_state: int = 63) -> Dict[str, object]:\n",
    "    \"\"\"Execute all causal estimators for documentation demos.\"\"\"\n",
    "\n",
    "    data = generate_synthetic_treatment_data(random_state=random_state)\n",
    "    ab_result = difference_in_means(data)\n",
    "    propensity_model = fit_propensity_model(data)\n",
    "    ipw_ate = estimate_ipw_ate(data, propensity_model)\n",
    "    dml_result = double_machine_learning(data)\n",
    "    uplift_result = two_model_uplift(data)\n",
    "    return {\n",
    "        \"data\": data,\n",
    "        \"ab_test\": ab_result,\n",
    "        \"ipw_ate\": ipw_ate,\n",
    "        \"double_ml\": dml_result,\n",
    "        \"uplift\": uplift_result,\n",
    "    }\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = run_causal_suite()\n",
    "    print(\"A/B lift:\", results[\"ab_test\"])\n",
    "    print(\"IPW ATE:\", results[\"ipw_ate\"])\n",
    "    print(\"Double ML ATE:\", results[\"double_ml\"].ate)\n",
    "    print(\"Uplift estimate:\", results[\"uplift\"].uplift)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
