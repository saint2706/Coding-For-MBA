Day 52 highlights how bagging, boosting, and stacking unlock better accuracy
than single estimators. Use the notebook or `solutions.py` helpers to:

- Generate a balanced synthetic dataset for comparing ensemble families.
- Train a random forest with out-of-bag (OOB) scoring and export feature
  importances for stakeholder-ready summaries.
- Fit a gradient boosting model, combine learners through stacking, and calibrate
  probabilities so the predictions can power downstream decision rules.

Execute `python Day_52_Ensemble_Methods/solutions.py` to print validation scores
for each ensemble configuration.

## Additional Materials

- [solutions.py](https://github.com/saint2706/Coding-For-MBA/blob/main/Day_52_Ensemble_Methods/solutions.py)
