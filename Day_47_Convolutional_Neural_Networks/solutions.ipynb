{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de310560",
   "metadata": {},
   "source": [
    "Reusable helpers for building and training a small CNN on MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "\n",
    "DEFAULT_SEED = 42\n",
    "\n",
    "\n",
    "def set_global_seed(seed: int = DEFAULT_SEED) -> None:\n",
    "    \"\"\"Synchronise NumPy and TensorFlow RNGs for deterministic runs.\"\"\"\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "\n",
    "def prepare_mnist_data(\n",
    "    normalize: bool = True,\n",
    ") -> Tuple[Tuple[np.ndarray, np.ndarray], Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"Load MNIST images, optionally normalise pixels, and add a channel axis.\"\"\"\n",
    "\n",
    "    (train_images, train_labels), (test_images, test_labels) = (\n",
    "        datasets.mnist.load_data()\n",
    "    )\n",
    "\n",
    "    train_images = train_images.astype(\"float32\")\n",
    "    test_images = test_images.astype(\"float32\")\n",
    "\n",
    "    if normalize:\n",
    "        train_images /= 255.0\n",
    "        test_images /= 255.0\n",
    "\n",
    "    train_images = train_images[..., tf.newaxis]\n",
    "    test_images = test_images[..., tf.newaxis]\n",
    "\n",
    "    return (train_images, train_labels), (test_images, test_labels)\n",
    "\n",
    "\n",
    "def build_cnn_model(\n",
    "    input_shape: Tuple[int, int, int] = (28, 28, 1),\n",
    "    num_classes: int = 10,\n",
    "    conv_filters: Tuple[int, int, int] = (32, 64, 64),\n",
    "    dense_units: int = 64,\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Create an MNIST classifier mirroring the tutorial architecture.\"\"\"\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    for index, filters in enumerate(conv_filters):\n",
    "        model.add(layers.Conv2D(filters, (3, 3), activation=\"relu\"))\n",
    "        if index < len(conv_filters) - 1:\n",
    "            model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(dense_units, activation=\"relu\"))\n",
    "    model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def compile_cnn_model(\n",
    "    model: tf.keras.Model,\n",
    "    optimizer: str = \"adam\",\n",
    "    loss: str = \"sparse_categorical_crossentropy\",\n",
    "    metrics: Tuple[str, ...] = (\"accuracy\",),\n",
    ") -> tf.keras.Model:\n",
    "    \"\"\"Compile the CNN with sensible defaults for classification.\"\"\"\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=list(metrics))\n",
    "    return model\n",
    "\n",
    "\n",
    "def train_cnn_model(\n",
    "    model: tf.keras.Model,\n",
    "    train_images: np.ndarray,\n",
    "    train_labels: np.ndarray,\n",
    "    *,\n",
    "    epochs: int = 5,\n",
    "    batch_size: int = 64,\n",
    "    validation_data: Tuple[np.ndarray, np.ndarray] | None = None,\n",
    "    validation_split: float = 0.0,\n",
    "    verbose: int = 1,\n",
    "    shuffle: bool = True,\n",
    ") -> tf.keras.callbacks.History:\n",
    "    \"\"\"Fit the CNN and return the training history.\"\"\"\n",
    "\n",
    "    history = model.fit(\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data,\n",
    "        validation_split=validation_split,\n",
    "        verbose=verbose,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return history\n",
    "\n",
    "\n",
    "def evaluate_cnn_model(\n",
    "    model: tf.keras.Model,\n",
    "    test_images: np.ndarray,\n",
    "    test_labels: np.ndarray,\n",
    "    *,\n",
    "    verbose: int = 2,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate the trained CNN on the test split.\"\"\"\n",
    "\n",
    "    return model.evaluate(test_images, test_labels, verbose=verbose, return_dict=True)\n",
    "\n",
    "\n",
    "def run_full_workflow(\n",
    "    *,\n",
    "    epochs: int = 5,\n",
    "    batch_size: int = 64,\n",
    "    verbose: int = 1,\n",
    "    seed: int = DEFAULT_SEED,\n",
    ") -> Tuple[tf.keras.callbacks.History, Dict[str, float], tf.keras.Model]:\n",
    "    \"\"\"Train and evaluate the CNN end-to-end, returning the artifacts.\"\"\"\n",
    "\n",
    "    set_global_seed(seed)\n",
    "    (train_images, train_labels), (test_images, test_labels) = prepare_mnist_data()\n",
    "    model = build_cnn_model(input_shape=train_images.shape[1:])\n",
    "    compile_cnn_model(model)\n",
    "    history = train_cnn_model(\n",
    "        model,\n",
    "        train_images,\n",
    "        train_labels,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(test_images, test_labels),\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    metrics = evaluate_cnn_model(model, test_images, test_labels, verbose=verbose)\n",
    "    return history, metrics, model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    history, metrics, model = run_full_workflow()\n",
    "\n",
    "    print(\"--- CNN for MNIST Classification ---\")\n",
    "    model.summary()\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Final training accuracy:\", history.history[\"accuracy\"][-1])\n",
    "    print(\"Test metrics:\")\n",
    "    for name, value in metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
