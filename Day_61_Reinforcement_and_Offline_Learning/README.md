# Day 61 – Reinforcement and Offline Learning

Reinforcement learning (RL) balances exploration and exploitation while offline evaluation keeps policies safe. After this lesson you can:

- Compare value-based, policy-based, and actor–critic methods across episodic control problems.
- Simulate contextual bandits and conservative offline policy evaluation with replay buffers and importance sampling.
- Analyse stability tricks: entropy bonuses, target networks, batch-constrained Q-learning, and doubly robust estimators.
- Reproduce seeded experiments that converge to expected reward thresholds for regression tests.

Execute `python Day_61_Reinforcement_and_Offline_Learning/solutions.py` to walk through deterministic policy optimisation, offline evaluation diagnostics, and bandit baselines.
