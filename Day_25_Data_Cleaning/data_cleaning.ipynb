{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e78de0",
   "metadata": {},
   "source": [
    "Day 25: Data Cleaning in Practice (Optimized)\n",
    "\n",
    "This script demonstrates common data cleaning techniques on a\n",
    "messy, real-world-style dataset using Pandas. This version includes\n",
    "performance optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa8ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the sales data by correcting data types, standardizing text,\n",
    "    and removing duplicates.\n",
    "    \"\"\"\n",
    "    # --- 1. Correcting Data Types ---\n",
    "    df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"])\n",
    "\n",
    "    # Optimized price cleaning using a single regex\n",
    "    df[\"Price\"] = df[\"Price\"].str.replace(r\"[$,]\", \"\", regex=True).astype(float)\n",
    "\n",
    "    # --- 2. Cleaning and Standardizing Text Data ---\n",
    "    df[\"Region\"] = df[\"Region\"].str.strip().str.lower()\n",
    "    df[\"Product\"] = df[\"Product\"].str.lower()\n",
    "    df[\"Region\"] = df[\"Region\"].replace({\"usa\": \"united states\"})\n",
    "\n",
    "    # --- 3. Handling Duplicates ---\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.drop_duplicates(subset=[\"Order ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load, clean, and inspect the data.\n",
    "    \"\"\"\n",
    "    # --- Load the Messy Data ---\n",
    "    resource_dir = Path(__file__).resolve().parent\n",
    "    data_path = resource_dir / \"messy_sales_data.csv\"\n",
    "\n",
    "    print(\"--- Loading and Inspecting Messy Data ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        print(\"Original data types (df.info()):\")\n",
    "        df.info()\n",
    "        print(\"\\nOriginal data head:\")\n",
    "        print(df.head())\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            \"Error: messy_sales_data.csv not found in the Day_25_Data_Cleaning folder.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # --- Clean the Data ---\n",
    "    df_cleaned = clean_sales_data(\n",
    "        df.copy()\n",
    "    )  # Use a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # --- Inspect Cleaned Data ---\n",
    "    print(\"\\n--- Inspecting Cleaned Data ---\")\n",
    "    print(\"\\nCleaned data types (df.info()):\")\n",
    "    df_cleaned.info()\n",
    "    print(\"\\nCleaned data head:\")\n",
    "    print(df_cleaned.head())\n",
    "    print(\"\\nUnique values in 'Region' column:\", df_cleaned[\"Region\"].unique())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
