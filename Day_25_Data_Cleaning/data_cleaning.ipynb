{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "360b3aba",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 25: Data Cleaning - The Most Important Skill in Analytics\n",
    "\n",
    "It's often said that data analysts spend about 80% of their time cleaning and preparing data. Messy, inconsistent data leads to incorrect analysis and bad business decisions. Learning to clean data effectively is a true superpower.\n",
    "\n",
    "## Common Data Cleaning Tasks\n",
    "\n",
    "- **Correcting Data Types:** Columns are often loaded with the wrong type (e.g., a 'Price' column with '$' symbols is read as a string). Use `.astype()` to convert columns to the correct type (e.g., `float`, `datetime64[ns]`).\n",
    "- **String Manipulation:** Use the `.str` accessor on a Series to apply string methods to every element at once (e.g., `df['Category'].str.lower()`, `df['Region'].str.strip()`).\n",
    "- **Standardizing Categories:** Use the `.replace()` method to consolidate inconsistent values (e.g., mapping \"USA\" and \"United States\" to a single category).\n",
    "- **Handling Duplicates:** Use `df.drop_duplicates()` to remove duplicate rows. The `subset` parameter lets you define which columns to check for duplicates (e.g., `subset=['OrderID']`).\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `data_cleaning.py`, has been refactored to encapsulate the entire cleaning process into a single, reusable function.\n",
    "\n",
    "1. **Review the Code:** Open `Day_25_Data_Cleaning/data_cleaning.py`. Examine the `clean_sales_data()` function, which performs all the cleaning steps on a DataFrame.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script. It will load the messy CSV, pass it to the cleaning function, and print the results.\n",
    "   ```bash\n",
    "   python Day_25_Data_Cleaning/data_cleaning.py\n",
    "   ```\n",
    "1. **Run the Tests:** The tests use a sample messy DataFrame created in memory to verify that the entire cleaning pipeline works as expected.\n",
    "   ```bash\n",
    "   pytest tests/test_day_25.py\n",
    "   ```\n",
    "\n",
    "## ðŸ’» Exercises: Day 25\n",
    "\n",
    "For these exercises, you will use the provided `messy_sales_data.csv` file.\n",
    "\n",
    "1. **Load and Clean:**\n",
    "\n",
    "   - In a new script (`my_solutions_25.py`), import `pandas` and the `clean_sales_data` function from the lesson script.\n",
    "   - Load the `messy_sales_data.csv` file into a DataFrame.\n",
    "   - Pass your DataFrame to the `clean_sales_data` function to get a cleaned version.\n",
    "\n",
    "1. **Verify the Cleaning:**\n",
    "\n",
    "   - On your new `cleaned_df`, perform the following checks and print the results:\n",
    "     - Use `.info()` to confirm that 'Order Date' is a datetime and 'Price' is a float.\n",
    "     - Print the unique values of the 'Product' column (`cleaned_df['Product'].unique()`) to confirm they are all lowercase.\n",
    "     - Check the shape of the original DataFrame versus the cleaned one to see how many rows were removed.\n",
    "\n",
    "ðŸŽ‰ **Incredible work!** Being able to take a messy, real-world dataset and turn it into a clean, analysis-ready format is arguably the most valuable skill a data analyst can possess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227bf91",
   "metadata": {},
   "source": [
    "Day 25: Data Cleaning in Practice (Optimized)\n",
    "\n",
    "This script demonstrates common data cleaning techniques on a\n",
    "messy, real-world-style dataset using Pandas. This version includes\n",
    "performance optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def clean_sales_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cleans the sales data by correcting data types, standardizing text,\n",
    "    and removing duplicates.\n",
    "    \"\"\"\n",
    "    # --- 1. Correcting Data Types ---\n",
    "    df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"])\n",
    "\n",
    "    # Optimized price cleaning using a single regex\n",
    "    df[\"Price\"] = df[\"Price\"].str.replace(r\"[$,]\", \"\", regex=True).astype(float)\n",
    "\n",
    "    # --- 2. Cleaning and Standardizing Text Data ---\n",
    "    df[\"Region\"] = df[\"Region\"].str.strip().str.lower()\n",
    "    df[\"Product\"] = df[\"Product\"].str.lower()\n",
    "    df[\"Region\"] = df[\"Region\"].replace({\"usa\": \"united states\"})\n",
    "\n",
    "    # --- 3. Handling Duplicates ---\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    df.drop_duplicates(subset=[\"Order ID\"], keep=\"first\", inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to load, clean, and inspect the data.\n",
    "    \"\"\"\n",
    "    # --- Load the Messy Data ---\n",
    "    resource_dir = Path(__file__).resolve().parent\n",
    "    data_path = resource_dir / \"messy_sales_data.csv\"\n",
    "\n",
    "    print(\"--- Loading and Inspecting Messy Data ---\")\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        print(\"Original data types (df.info()):\")\n",
    "        df.info()\n",
    "        print(\"\\nOriginal data head:\")\n",
    "        print(df.head())\n",
    "    except FileNotFoundError:\n",
    "        print(\n",
    "            \"Error: messy_sales_data.csv not found in the Day_25_Data_Cleaning folder.\"\n",
    "        )\n",
    "        return\n",
    "\n",
    "    # --- Clean the Data ---\n",
    "    df_cleaned = clean_sales_data(\n",
    "        df.copy()\n",
    "    )  # Use a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # --- Inspect Cleaned Data ---\n",
    "    print(\"\\n--- Inspecting Cleaned Data ---\")\n",
    "    print(\"\\nCleaned data types (df.info()):\")\n",
    "    df_cleaned.info()\n",
    "    print(\"\\nCleaned data head:\")\n",
    "    print(df_cleaned.head())\n",
    "    print(\"\\nUnique values in 'Region' column:\", df_cleaned[\"Region\"].unique())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
