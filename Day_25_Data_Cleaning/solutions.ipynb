{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c0b49e",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Day 25: Data Cleaning - The Most Important Skill in Analytics\n",
    "\n",
    "It's often said that data analysts spend about 80% of their time cleaning and preparing data. Messy, inconsistent data leads to incorrect analysis and bad business decisions. Learning to clean data effectively is a true superpower.\n",
    "\n",
    "## Common Data Cleaning Tasks\n",
    "\n",
    "- **Correcting Data Types:** Columns are often loaded with the wrong type (e.g., a 'Price' column with '$' symbols is read as a string). Use `.astype()` to convert columns to the correct type (e.g., `float`, `datetime64[ns]`).\n",
    "- **String Manipulation:** Use the `.str` accessor on a Series to apply string methods to every element at once (e.g., `df['Category'].str.lower()`, `df['Region'].str.strip()`).\n",
    "- **Standardizing Categories:** Use the `.replace()` method to consolidate inconsistent values (e.g., mapping \"USA\" and \"United States\" to a single category).\n",
    "- **Handling Duplicates:** Use `df.drop_duplicates()` to remove duplicate rows. The `subset` parameter lets you define which columns to check for duplicates (e.g., `subset=['OrderID']`).\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "Before you begin, ensure you have followed the setup instructions in the main [README.md](../../README.md) to set up your virtual environment and install the required libraries.\n",
    "\n",
    "## Exploring the Refactored Code\n",
    "\n",
    "The script for this lesson, `data_cleaning.py`, has been refactored to encapsulate the entire cleaning process into a single, reusable function.\n",
    "\n",
    "1. **Review the Code:** Open `Day_25_Data_Cleaning/data_cleaning.py`. Examine the `clean_sales_data()` function, which performs all the cleaning steps on a DataFrame.\n",
    "1. **Run the Script:** From the root directory of the project (`Coding-For-MBA`), run the script. It will load the messy CSV, pass it to the cleaning function, and print the results.\n",
    "   ```bash\n",
    "   python Day_25_Data_Cleaning/data_cleaning.py\n",
    "   ```\n",
    "1. **Run the Tests:** The tests use a sample messy DataFrame created in memory to verify that the entire cleaning pipeline works as expected.\n",
    "   ```bash\n",
    "   pytest tests/test_day_25.py\n",
    "   ```\n",
    "\n",
    "## ðŸ’» Exercises: Day 25\n",
    "\n",
    "For these exercises, you will use the provided `messy_sales_data.csv` file.\n",
    "\n",
    "1. **Load and Clean:**\n",
    "\n",
    "   - In a new script (`my_solutions_25.py`), import `pandas` and the `clean_sales_data` function from the lesson script.\n",
    "   - Load the `messy_sales_data.csv` file into a DataFrame.\n",
    "   - Pass your DataFrame to the `clean_sales_data` function to get a cleaned version.\n",
    "\n",
    "1. **Verify the Cleaning:**\n",
    "\n",
    "   - On your new `cleaned_df`, perform the following checks and print the results:\n",
    "     - Use `.info()` to confirm that 'Order Date' is a datetime and 'Price' is a float.\n",
    "     - Print the unique values of the 'Product' column (`cleaned_df['Product'].unique()`) to confirm they are all lowercase.\n",
    "     - Check the shape of the original DataFrame versus the cleaned one to see how many rows were removed.\n",
    "\n",
    "ðŸŽ‰ **Incredible work!** Being able to take a messy, real-world dataset and turn it into a clean, analysis-ready format is arguably the most valuable skill a data analyst can possess."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76aaef79",
   "metadata": {},
   "source": [
    "Day 25: Solutions to Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0f2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# --- Exercise 1: Load and Initial Clean ---\n",
    "print(\"--- Solution to Exercise 1 ---\")\n",
    "resource_dir = Path(__file__).resolve().parent\n",
    "data_path = resource_dir / \"messy_sales_data.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(\"Original DataFrame info:\")\n",
    "    df.info()\n",
    "\n",
    "    # Convert 'Order Date' to datetime\n",
    "    df[\"Order Date\"] = pd.to_datetime(df[\"Order Date\"])\n",
    "    print(\"\\n'Order Date' column converted to datetime.\")\n",
    "\n",
    "    # Clean and convert 'Price' to float\n",
    "    df[\"Price\"] = df[\"Price\"].str.replace(\"$\", \"\").str.replace(\",\", \"\").astype(float)\n",
    "    print(\"'Price' column cleaned and converted to float.\")\n",
    "\n",
    "    # Clean 'Region' column whitespace\n",
    "    df[\"Region\"] = df[\"Region\"].str.strip()\n",
    "    print(\"'Region' column whitespace stripped.\")\n",
    "\n",
    "    print(\"\\nDataFrame info after initial cleaning:\")\n",
    "    df.info()\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"Error: messy_sales_data.csv not found in the Day_25_Data_Cleaning folder.\"\n",
    "        \" Keep the CSV beside this script.\"\n",
    "    )\n",
    "    df = pd.DataFrame()\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# --- Exercise 2: Standardize Categories ---\n",
    "print(\"--- Solution to Exercise 2 ---\")\n",
    "if not df.empty:\n",
    "    # Standardize 'Product' column to lowercase\n",
    "    df[\"Product\"] = df[\"Product\"].str.lower()\n",
    "    print(\"'Product' column standardized to lowercase.\")\n",
    "    print(f\"Unique product values: {df['Product'].unique()}\")\n",
    "\n",
    "    # Standardize 'Region' column to 'USA'\n",
    "    df[\"Region\"] = df[\"Region\"].replace({\"United States\": \"USA\"})\n",
    "    print(\"'Region' column standardized to 'USA'.\")\n",
    "    print(f\"Unique region values: {df['Region'].unique()}\")\n",
    "else:\n",
    "    print(\"DataFrame not available for this exercise.\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "\n",
    "# --- Exercise 3: Handle Duplicates ---\n",
    "print(\"--- Solution to Exercise 3 ---\")\n",
    "if not df.empty:\n",
    "    # Check for and count fully duplicate rows\n",
    "    num_duplicates = df.duplicated().sum()\n",
    "    print(f\"Number of fully duplicate rows found: {num_duplicates}\")\n",
    "\n",
    "    # Create df_cleaned by removing full duplicates\n",
    "    df_cleaned = df.drop_duplicates()\n",
    "    print(f\"Shape of original df: {df.shape}\")\n",
    "    print(f\"Shape after dropping duplicates (df_cleaned): {df_cleaned.shape}\")\n",
    "\n",
    "    # Check for duplicate Order IDs\n",
    "    num_duplicate_ids = df_cleaned.duplicated(subset=[\"Order ID\"]).sum()\n",
    "    print(f\"\\nNumber of duplicate Order IDs found: {num_duplicate_ids}\")\n",
    "\n",
    "    # Create df_final by removing duplicate Order IDs\n",
    "    df_final = df_cleaned.drop_duplicates(subset=[\"Order ID\"], keep=\"first\")\n",
    "    print(f\"Shape after dropping duplicate Order IDs (df_final): {df_final.shape}\")\n",
    "\n",
    "    print(\"\\nFinal cleaned DataFrame head:\")\n",
    "    print(df_final.head())\n",
    "else:\n",
    "    print(\"DataFrame not available for this exercise.\")\n",
    "print(\"-\" * 20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
