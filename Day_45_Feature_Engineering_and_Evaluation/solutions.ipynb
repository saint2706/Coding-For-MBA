{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96b3af0f",
   "metadata": {},
   "source": [
    "# Day 45: Feature Engineering & Model Evaluation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Day 45 demonstrates how thoughtful preprocessing and rigorous evaluation\n",
    "combine to build trustworthy models:\n",
    "\n",
    "- **Feature engineering pipelines** clean, scale, and encode raw columns so\n",
    "  downstream estimators receive consistent numeric inputs.\n",
    "- **Evaluation workflows** compare predictions against held-out data using\n",
    "  confusion matrices and rich classification reports.\n",
    "\n",
    "Install scikit-learn before exploring the examples:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "## What's inside\n",
    "\n",
    "- `solutions.py` – helper functions for assembling preprocessing pipelines,\n",
    "  transforming the toy dataset, training a logistic regression model, and\n",
    "  returning evaluation metrics.\n",
    "- `README.md` – lesson overview (this document).\n",
    "\n",
    "## Running the lesson script\n",
    "\n",
    "Execute the end-to-end walkthrough, which prints processed feature arrays,\n",
    "confusion matrix details, and a classification report:\n",
    "\n",
    "```bash\n",
    "python Day_45_Feature_Engineering_and_Evaluation/solutions.py\n",
    "```\n",
    "\n",
    "## Running the tests\n",
    "\n",
    "Run the dedicated Day 45 tests to validate the preprocessing and evaluation\n",
    "utilities:\n",
    "\n",
    "```bash\n",
    "pytest tests/test_day_45.py\n",
    "```\n",
    "\n",
    "To execute the entire project test suite, run `pytest` from the repository\n",
    "root.\n",
    "\n",
    "## Further exploration\n",
    "\n",
    "- Swap in additional categorical columns and confirm that the preprocessing\n",
    "  pipeline scales automatically.\n",
    "- Replace the logistic regression classifier in `build_model_pipeline` with\n",
    "  another estimator (e.g., RandomForestClassifier) and compare the resulting\n",
    "  confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08a497",
   "metadata": {},
   "source": [
    "Composable feature engineering and evaluation utilities for Day 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, Iterable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "\n",
    "def create_sample_dataframe() -> pd.DataFrame:\n",
    "    \"\"\"Return the toy purchase dataset used in the lesson.\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"age\": [25, 30, 35, 40, np.nan, 45, 50],\n",
    "        \"salary\": [50000, 60000, np.nan, 80000, 90000, 100000, 110000],\n",
    "        \"city\": [\n",
    "            \"New York\",\n",
    "            \"London\",\n",
    "            \"Paris\",\n",
    "            \"New York\",\n",
    "            \"London\",\n",
    "            \"Tokyo\",\n",
    "            \"Paris\",\n",
    "        ],\n",
    "        \"purchased\": [0, 1, 0, 1, 1, 0, 1],\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def build_preprocessing_pipeline(\n",
    "    numeric_features: Iterable[str] = (\"age\", \"salary\"),\n",
    "    categorical_features: Iterable[str] = (\"city\",),\n",
    ") -> ColumnTransformer:\n",
    "    \"\"\"Create a ColumnTransformer that handles numeric and categorical columns.\"\"\"\n",
    "\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, list(numeric_features)),\n",
    "            (\"cat\", categorical_transformer, list(categorical_features)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def preprocess_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    preprocessor: ColumnTransformer | None = None,\n",
    ") -> Tuple[np.ndarray, pd.Series, ColumnTransformer]:\n",
    "    \"\"\"Fit the preprocessing pipeline and return the transformed feature matrix.\"\"\"\n",
    "\n",
    "    if \"purchased\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'purchased' target column in the dataframe.\")\n",
    "\n",
    "    X = df.drop(\"purchased\", axis=1)\n",
    "    y = df[\"purchased\"]\n",
    "    preprocessor = preprocessor or build_preprocessing_pipeline()\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    return X_processed, y, preprocessor\n",
    "\n",
    "\n",
    "def build_model_pipeline(preprocessor: ColumnTransformer) -> Pipeline:\n",
    "    \"\"\"Combine preprocessing with a logistic regression classifier.\"\"\"\n",
    "\n",
    "    return Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", preprocessor),\n",
    "            (\"classifier\", LogisticRegression()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_model(\n",
    "    df: pd.DataFrame,\n",
    "    test_size: float = 0.3,\n",
    "    random_state: int | None = 42,\n",
    ") -> Tuple[Pipeline, Dict[str, object]]:\n",
    "    \"\"\"Train the pipeline and compute evaluation metrics on a test split.\"\"\"\n",
    "\n",
    "    if \"purchased\" not in df.columns:\n",
    "        raise ValueError(\"Expected 'purchased' target column in the dataframe.\")\n",
    "\n",
    "    X = df.drop(\"purchased\", axis=1)\n",
    "    y = df[\"purchased\"]\n",
    "    preprocessor = build_preprocessing_pipeline()\n",
    "    pipeline = build_model_pipeline(preprocessor)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    metrics: Dict[str, object] = {\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred),\n",
    "        \"classification_report\": classification_report(y_test, y_pred, zero_division=0),\n",
    "    }\n",
    "    return pipeline, metrics\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- Feature Engineering Example ---\")\n",
    "    dataframe = create_sample_dataframe()\n",
    "    print(\"Original DataFrame:\")\n",
    "    print(dataframe)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    processed, target, fitted_preprocessor = preprocess_dataframe(dataframe)\n",
    "    print(\"Shape of data after preprocessing:\", processed.shape)\n",
    "    print(\"Note: 'city' was expanded into multiple columns by OneHotEncoder.\")\n",
    "    print(\"Transformed data (first 3 rows):\")\n",
    "    print(processed[:3])\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"\\n--- Model Evaluation Example ---\")\n",
    "    model, metrics = evaluate_model(dataframe)\n",
    "    confusion = metrics[\"confusion_matrix\"]\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion)\n",
    "    print(\"TN | FP\")\n",
    "    print(\"FN | TP\")\n",
    "    print(\n",
    "        f\"True Negatives (TN): {confusion[0, 0]} | False Positives (FP): {confusion[0, 1]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"False Negatives (FN): {confusion[1, 0]} | True Positives (TP): {confusion[1, 1]}\"\n",
    "    )\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics[\"classification_report\"])\n",
    "    print(\n",
    "        \"This report provides a breakdown of precision, recall, and f1-score for each class.\"\n",
    "    )\n",
    "    print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
