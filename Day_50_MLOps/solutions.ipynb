{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fad5d31",
   "metadata": {},
   "source": [
    "Reusable helpers for the Day 50 MLOps lesson.\n",
    "\n",
    "The original script demonstrated how to train, persist, load, and reuse a\n",
    "scikit-learn model.  The logic now lives in functions that can be imported from\n",
    "tests or other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac60be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from collections import Counter\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "from typing import Iterable, Optional, Sequence, Tuple\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_iris_model(\n",
    "    *,\n",
    "    test_size: float = 0.2,\n",
    "    random_state: int = 42,\n",
    "    max_iter: int = 200,\n",
    "    subset_size: Optional[int] = None,\n",
    ") -> Tuple[LogisticRegression, float, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Train a Logistic Regression model on the Iris dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test_size:\n",
    "        Fraction of the dataset to hold back for evaluation.\n",
    "    random_state:\n",
    "        Seed that controls the train/test split and optional sub-sampling.\n",
    "    max_iter:\n",
    "        Maximum number of iterations for the Logistic Regression solver.\n",
    "    subset_size:\n",
    "        If provided, draw a deterministic subset of this size before\n",
    "        training. This is useful for demonstrations and tests where you want a\n",
    "        smaller, reproducible dataset.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model:\n",
    "        The trained scikit-learn estimator.\n",
    "    accuracy:\n",
    "        Accuracy on the held-out test set.\n",
    "    X_test, y_test:\n",
    "        The evaluation features and labels so callers can verify behaviour.\n",
    "    target_names:\n",
    "        Names of the Iris species corresponding to prediction indices.\n",
    "    \"\"\"\n",
    "\n",
    "    iris = load_iris()\n",
    "    X, y = iris.data, iris.target\n",
    "    full_classes = np.unique(iris.target)\n",
    "\n",
    "    if subset_size is not None:\n",
    "        if subset_size <= 0:\n",
    "            raise ValueError(\"subset_size must be a positive integer\")\n",
    "        if subset_size > len(X):\n",
    "            raise ValueError(\"subset_size cannot exceed the dataset size\")\n",
    "        rng = np.random.RandomState(random_state)\n",
    "        indices = rng.choice(len(X), subset_size, replace=False)\n",
    "        X = X[indices]\n",
    "        y = y[indices]\n",
    "\n",
    "    present_classes = np.unique(y)\n",
    "    missing_classes = sorted(set(full_classes) - set(present_classes))\n",
    "    if missing_classes:\n",
    "        raise ValueError(\n",
    "            \"Sub-sampled dataset is missing the following Iris classes: \"\n",
    "            f\"{missing_classes}. Increase the subset_size to include all classes.\"\n",
    "        )\n",
    "\n",
    "    class_counts = Counter(int(label) for label in np.asarray(y))\n",
    "    y_length = len(y)\n",
    "    effective_test_ratio: Optional[float] = None\n",
    "    if isinstance(test_size, (float, int)):\n",
    "        if isinstance(test_size, float):\n",
    "            if not 0 < test_size < 1:\n",
    "                raise ValueError(\"test_size must be between 0 and 1 when provided as a float\")\n",
    "            effective_test_ratio = test_size\n",
    "        else:\n",
    "            test_size_int = int(test_size)\n",
    "            if test_size_int <= 0 or test_size_int >= y_length:\n",
    "                raise ValueError(\n",
    "                    \"test_size must leave at least one sample in both the train and test sets\"\n",
    "                )\n",
    "            effective_test_ratio = test_size_int / y_length\n",
    "\n",
    "    for label in full_classes:\n",
    "        count = class_counts[int(label)]\n",
    "        if count < 2:\n",
    "            raise ValueError(\n",
    "                \"Sub-sampled dataset must contain at least two samples per class to allow a stratified split.\"\n",
    "            )\n",
    "        if effective_test_ratio is not None:\n",
    "            test_allocation = ceil(count * effective_test_ratio)\n",
    "            if test_allocation == 0 or test_allocation >= count:\n",
    "                raise ValueError(\n",
    "                    \"Sub-sampled dataset does not have enough samples of class \"\n",
    "                    f\"{label} to satisfy test_size={test_size}. \"\n",
    "                    \"Increase the subset_size or adjust test_size.\"\n",
    "                )\n",
    "\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            random_state=random_state,\n",
    "            stratify=y,\n",
    "        )\n",
    "    except ValueError as exc:\n",
    "        raise ValueError(\n",
    "            \"Unable to perform a stratified train/test split with the requested \"\n",
    "            \"parameters. Ensure each class has sufficient samples for the chosen \"\n",
    "            \"test_size.\"\n",
    "        ) from exc\n",
    "\n",
    "    model = LogisticRegression(max_iter=max_iter)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    return model, accuracy, X_test, y_test, iris.target_names\n",
    "\n",
    "\n",
    "def save_model(model: LogisticRegression, path: Path | str) -> Path:\n",
    "    \"\"\"Persist the trained model to disk and return the resolved path.\"\"\"\n",
    "\n",
    "    path = Path(path).expanduser().resolve()\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    joblib.dump(model, path)\n",
    "    return path\n",
    "\n",
    "\n",
    "def load_model(path: Path | str) -> LogisticRegression:\n",
    "    \"\"\"Load a persisted model from disk.\"\"\"\n",
    "\n",
    "    path = Path(path)\n",
    "    return joblib.load(path)\n",
    "\n",
    "\n",
    "def predict_sample(\n",
    "    model: LogisticRegression,\n",
    "    sample: Iterable[float],\n",
    "    target_names: Optional[Sequence[str]] = None,\n",
    ") -> Tuple[int, Optional[str]]:\n",
    "    \"\"\"Predict the Iris class for a single feature vector.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model:\n",
    "        A trained scikit-learn estimator.\n",
    "    sample:\n",
    "        Iterable of feature values (sepal length, sepal width, petal length,\n",
    "        petal width).\n",
    "    target_names:\n",
    "        Optional sequence of class labels. If provided, the corresponding name\n",
    "        is returned alongside the numeric prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    array = np.asarray(sample, dtype=float)\n",
    "    if array.ndim == 1:\n",
    "        array = array.reshape(1, -1)\n",
    "    prediction = model.predict(array)[0]\n",
    "    name = None\n",
    "    if target_names is not None:\n",
    "        name = target_names[prediction]\n",
    "    return prediction, name\n",
    "\n",
    "\n",
    "def _demo() -> None:\n",
    "    \"\"\"Replicate the original script as a simple CLI demonstration.\"\"\"\n",
    "\n",
    "    print(\"--- Model Persistence Example ---\")\n",
    "    model, accuracy, X_test, y_test, target_names = train_iris_model()\n",
    "    print(f\"Model trained with an accuracy of: {accuracy * 100:.2f}%\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    model_filename = save_model(model, \"iris_model.joblib\")\n",
    "    print(f\"Model saved to '{model_filename}'\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    print(\"Loading model from file...\")\n",
    "    loaded_model = load_model(model_filename)\n",
    "    print(\"Model loaded successfully.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    new_sample = np.array([6.0, 2.5, 4.5, 1.5])\n",
    "    prediction, predicted_class_name = predict_sample(\n",
    "        loaded_model, new_sample, target_names\n",
    "    )\n",
    "\n",
    "    print(\"--- Making a Prediction with the Loaded Model ---\")\n",
    "    print(f\"New sample data: {new_sample.tolist()}\")\n",
    "    print(f\"Predicted class index: {prediction}\")\n",
    "    print(f\"Predicted class name: '{predicted_class_name}'\")\n",
    "    print(\"This demonstrates that our saved model retains its knowledge.\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\n",
    "        \"\\nCheck out 'bonus_flask_api.py' for an example of how to serve this model in a web API.\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    _demo()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
