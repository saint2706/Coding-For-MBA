# Day 62 â€“ Model Interpretability and Fairness

Explainable and responsible AI practices underpin trustworthy analytics. After this lesson you will:

- Compute additive SHAP-style attributions for linear models and verify they sum to the predicted score.
- Fit lightweight LIME surrogates around individual observations using locally weighted regression.
- Produce counterfactual examples that respect feature bounds to meet target outcomes.
- Quantify bias with statistical parity, disparate impact, and equal opportunity metrics.
- Apply simple reweighing mitigation to close gaps in simulated lending data.

Run `python Day_62_Model_Interpretability_and_Fairness/solutions.py` to walk through interpretability utilities, fairness diagnostics, and mitigation experiments on deterministic toy datasets.
