{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f187be3e",
   "metadata": {},
   "source": [
    "# Day 65 – MLOps Pipelines and CI/CD Automation\n",
    "\n",
    "Day 50 introduced model persistence. Day 65 expands that foundation into\n",
    "production-grade automation that glues together feature engineering,\n",
    "training, registration, and deployment inside a repeatable delivery\n",
    "pipeline.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "- **Feature stores** – Design entities, feature views, and point-in-time\n",
    "  joins that keep online/offline data consistent across training and\n",
    "  inference.\n",
    "- **Model registries** – Promote trained artefacts through staging,\n",
    "  production, and archival stages with metadata-rich lineage tracking.\n",
    "- **Workflow orchestration** – Compare how Apache Airflow DAGs and\n",
    "  Prefect flows coordinate complex ML tasks with retries, schedules, and\n",
    "  parameterised runs.\n",
    "- **Continuous integration and delivery** – Implement GitHub Actions\n",
    "  workflows that lint, test, train, and roll out models with automated\n",
    "  safety gates and human approvals when necessary.\n",
    "\n",
    "## Hands-on practice\n",
    "\n",
    "`solutions.py` ships a lightweight pipeline simulator that mirrors a\n",
    "feature store refresh, model training job, model registry promotion, and\n",
    "GitHub Actions deployment stage. The tasks are wired together with a\n",
    "miniature DAG executor inspired by Airflow/PyPrefect semantics so you\n",
    "can experiment with dependency resolution locally.\n",
    "\n",
    "Run the module to see the orchestration trace:\n",
    "\n",
    "```bash\n",
    "python Day_65_MLOps_Pipelines_and_CI/solutions.py\n",
    "```\n",
    "\n",
    "The included tests (`tests/test_day_65.py`) stub raw feature inputs and\n",
    "assert that the DAG executes in topological order, promoting a versioned\n",
    "model artefact only after automated evaluation passes.\n",
    "\n",
    "## Extend the exercise\n",
    "\n",
    "- Swap the in-memory feature store with Feast or Tecton to practice\n",
    "  managing online/offline materialisation.\n",
    "- Replace the registry stub with MLflow’s model registry to integrate\n",
    "  experiment tracking and stage transitions.\n",
    "- Export the DAG to YAML/JSON and feed it into Airflow or Prefect for a\n",
    "  production-ready orchestration pattern.\n",
    "- Fork the GitHub Actions example into your repository to add matrix\n",
    "  testing (Python versions, CPU vs GPU runners) and continuous delivery\n",
    "  to Kubernetes, SageMaker, or Vertex AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb6bf9",
   "metadata": {},
   "source": [
    "Utility helpers for orchestrating an end-to-end MLOps pipeline.\n",
    "\n",
    "The module intentionally mirrors the stages that appear in a production\n",
    "GitHub Actions workflow: refresh a feature store, train and evaluate a\n",
    "model, register the resulting artefact, and perform a deployment gate.\n",
    "\n",
    "Instead of depending on heavy external services, the code uses\n",
    "lightweight, deterministic stubs so unit tests can simulate an Apache\n",
    "Airflow or Prefect DAG locally. Each task receives a consolidated\n",
    "context dictionary (similar to Airflow's XCom or Prefect's task result)\n",
    "and may add new keys for downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99b5257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import UTC, datetime\n",
    "from typing import (\n",
    "    Any,\n",
    "    Callable,\n",
    "    Dict,\n",
    "    Iterable,\n",
    "    List,\n",
    "    Mapping,\n",
    "    MutableMapping,\n",
    "    Optional,\n",
    ")\n",
    "\n",
    "FeatureRow = Mapping[str, Any]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    \"\"\"Represents a node in an orchestration graph.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    name:\n",
    "        Unique identifier for the task. Names are used to resolve\n",
    "        dependencies and to expose results in the execution context.\n",
    "    run:\n",
    "        Callable that receives the merged execution context and returns a\n",
    "        value that is stored under ``name`` for downstream tasks.\n",
    "    upstream:\n",
    "        Optional list of task names that must finish before this task\n",
    "        executes. The dependency semantics align with Airflow DAGs and\n",
    "        Prefect flows.\n",
    "    \"\"\"\n",
    "\n",
    "    name: str\n",
    "    run: Callable[[MutableMapping[str, Any]], Any]\n",
    "    upstream: List[str] = field(default_factory=list)\n",
    "\n",
    "\n",
    "class PipelineDAG:\n",
    "    \"\"\"A minimal directed acyclic graph executor for ML pipelines.\"\"\"\n",
    "\n",
    "    def __init__(self, tasks: Iterable[Task]):\n",
    "        self._tasks: Dict[str, Task] = {}\n",
    "        for task in tasks:\n",
    "            if task.name in self._tasks:\n",
    "                raise ValueError(f\"Duplicate task name detected: {task.name}\")\n",
    "            self._tasks[task.name] = task\n",
    "        for task in self._tasks.values():\n",
    "            for dependency in task.upstream:\n",
    "                if dependency not in self._tasks:\n",
    "                    raise ValueError(\n",
    "                        f\"Task '{task.name}' references unknown dependency '{dependency}'\"\n",
    "                    )\n",
    "\n",
    "    @property\n",
    "    def tasks(self) -> Dict[str, Task]:\n",
    "        return self._tasks\n",
    "\n",
    "    def topological_order(self) -> List[str]:\n",
    "        \"\"\"Return a deterministic topological ordering of the tasks.\"\"\"\n",
    "\n",
    "        temporary_marks: set[str] = set()\n",
    "        permanent_marks: set[str] = set()\n",
    "        ordered: List[str] = []\n",
    "\n",
    "        def visit(node_name: str) -> None:\n",
    "            if node_name in permanent_marks:\n",
    "                return\n",
    "            if node_name in temporary_marks:\n",
    "                raise ValueError(\"Cycle detected in DAG definition\")\n",
    "            temporary_marks.add(node_name)\n",
    "            node = self._tasks[node_name]\n",
    "            for dependency in node.upstream:\n",
    "                visit(dependency)\n",
    "            permanent_marks.add(node_name)\n",
    "            temporary_marks.remove(node_name)\n",
    "            ordered.append(node_name)\n",
    "\n",
    "        for name in sorted(self._tasks):\n",
    "            if name not in permanent_marks:\n",
    "                visit(name)\n",
    "        return ordered\n",
    "\n",
    "    def execute(\n",
    "        self, base_context: Optional[MutableMapping[str, Any]] = None\n",
    "    ) -> Dict[str, Any]:\n",
    "        \"\"\"Execute tasks respecting dependencies.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        base_context:\n",
    "            Optional dictionary containing static inputs (for example raw\n",
    "            features or configuration). Tasks may mutate this dictionary,\n",
    "            mimicking orchestration platforms that provide shared context\n",
    "            objects.\n",
    "        \"\"\"\n",
    "\n",
    "        context: MutableMapping[str, Any]\n",
    "        if base_context is None:\n",
    "            context = {}\n",
    "        else:\n",
    "            context = base_context\n",
    "        ordered = self.topological_order()\n",
    "        for name in ordered:\n",
    "            task = self._tasks[name]\n",
    "            context[name] = task.run(context)\n",
    "        context[\"execution_order\"] = ordered\n",
    "        return context\n",
    "\n",
    "\n",
    "def upsert_feature_store(rows: Iterable[FeatureRow]) -> Dict[str, FeatureRow]:\n",
    "    \"\"\"Materialise feature rows into an in-memory feature store.\n",
    "\n",
    "    The function keeps the most recent row for each primary key and\n",
    "    stamps the ingestion time. Production feature stores (Feast, Tecton,\n",
    "    Vertex AI Feature Store) provide similar semantics.\n",
    "    \"\"\"\n",
    "\n",
    "    feature_store: Dict[str, FeatureRow] = {}\n",
    "    for row in rows:\n",
    "        entity_id = str(row.get(\"entity_id\"))\n",
    "        feature_store[entity_id] = {\n",
    "            **row,\n",
    "            \"ingested_at\": datetime.now(UTC).isoformat(timespec=\"seconds\"),\n",
    "        }\n",
    "    return feature_store\n",
    "\n",
    "\n",
    "def train_model_from_store(store: Mapping[str, FeatureRow]) -> Dict[str, Any]:\n",
    "    \"\"\"Train and evaluate a trivial model using feature store contents.\"\"\"\n",
    "\n",
    "    feature_values = [row.get(\"feature_value\", 0.0) for row in store.values()]\n",
    "    if not feature_values:\n",
    "        raise ValueError(\"Feature store is empty; cannot train model\")\n",
    "    avg_feature = sum(feature_values) / len(feature_values)\n",
    "    # The \"model\" is encoded as a slope anchored by the mean feature value.\n",
    "    model_artifact = {\n",
    "        \"parameters\": {\"slope\": avg_feature / (1 + abs(avg_feature))},\n",
    "        \"metrics\": {\"validation_accuracy\": 0.8 + (avg_feature % 0.2)},\n",
    "    }\n",
    "    return model_artifact\n",
    "\n",
    "\n",
    "def register_model(\n",
    "    model: Mapping[str, Any], *, name: str, stage: str\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Record model metadata as if interacting with an MLflow-style registry.\"\"\"\n",
    "\n",
    "    if \"metrics\" not in model:\n",
    "        raise KeyError(\"Model metadata must include 'metrics'\")\n",
    "    version = datetime.now(UTC).strftime(\"%Y%m%d%H%M%S\")\n",
    "    registry_entry = {\n",
    "        \"name\": name,\n",
    "        \"version\": version,\n",
    "        \"stage\": stage,\n",
    "        \"metrics\": model[\"metrics\"],\n",
    "    }\n",
    "    return registry_entry\n",
    "\n",
    "\n",
    "def github_actions_deploy(entry: Mapping[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Simulate a GitHub Actions job that deploys a registered model.\"\"\"\n",
    "\n",
    "    if entry.get(\"stage\") != \"Staging\":\n",
    "        return {\n",
    "            \"status\": \"skipped\",\n",
    "            \"reason\": \"Only staging models deploy automatically\",\n",
    "        }\n",
    "    if entry.get(\"metrics\", {}).get(\"validation_accuracy\", 0.0) < 0.85:\n",
    "        return {\n",
    "            \"status\": \"failed\",\n",
    "            \"reason\": \"Quality gate failed\",\n",
    "        }\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"environment\": \"production\",\n",
    "        \"commit_sha\": \"demo-sha\",\n",
    "    }\n",
    "\n",
    "\n",
    "def build_mlops_pipeline(raw_rows: Iterable[FeatureRow]) -> PipelineDAG:\n",
    "    \"\"\"Construct the pipeline DAG with deterministic task wiring.\"\"\"\n",
    "\n",
    "    # Persist raw rows in the base context so the feature-store task can\n",
    "    # consume them. The orchestrator will attach results by task name.\n",
    "    base_context = {\"raw_rows\": list(raw_rows)}\n",
    "\n",
    "    def feature_task(context: MutableMapping[str, Any]) -> Dict[str, FeatureRow]:\n",
    "        return upsert_feature_store(context[\"raw_rows\"])\n",
    "\n",
    "    def training_task(context: MutableMapping[str, Any]) -> Dict[str, Any]:\n",
    "        return train_model_from_store(context[\"feature_store\"])\n",
    "\n",
    "    def registry_task(context: MutableMapping[str, Any]) -> Dict[str, Any]:\n",
    "        return register_model(\n",
    "            context[\"model_training\"], name=\"churn_model\", stage=\"Staging\"\n",
    "        )\n",
    "\n",
    "    def deployment_task(context: MutableMapping[str, Any]) -> Dict[str, Any]:\n",
    "        return github_actions_deploy(context[\"model_registry\"])\n",
    "\n",
    "    tasks = [\n",
    "        Task(name=\"feature_store\", run=feature_task),\n",
    "        Task(name=\"model_training\", run=training_task, upstream=[\"feature_store\"]),\n",
    "        Task(name=\"model_registry\", run=registry_task, upstream=[\"model_training\"]),\n",
    "        Task(name=\"deployment\", run=deployment_task, upstream=[\"model_registry\"]),\n",
    "    ]\n",
    "\n",
    "    dag = PipelineDAG(tasks)\n",
    "    # Attach the base context so callers can re-use it between runs.\n",
    "    dag.base_context = base_context  # type: ignore[attr-defined]\n",
    "    return dag\n",
    "\n",
    "\n",
    "def run_pipeline(raw_rows: Iterable[FeatureRow]) -> Dict[str, Any]:\n",
    "    \"\"\"Helper for scripts/tests: build the DAG and execute it.\"\"\"\n",
    "\n",
    "    dag = build_mlops_pipeline(raw_rows)\n",
    "    context = getattr(dag, \"base_context\", {})\n",
    "    return dag.execute(context)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rows = [\n",
    "        {\"entity_id\": 1, \"feature_value\": 0.42},\n",
    "        {\"entity_id\": 2, \"feature_value\": 0.58},\n",
    "    ]\n",
    "    results = run_pipeline(rows)\n",
    "    print(\"Execution order:\", results[\"execution_order\"])  # noqa: T201\n",
    "    print(\"Deployment status:\", results[\"deployment\"])  # noqa: T201"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
